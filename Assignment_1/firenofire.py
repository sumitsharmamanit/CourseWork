# -*- coding: utf-8 -*-
"""FirenoFire.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qT5uzxLtALpMfCb5VlIpQehbjKDAOmFq

# Fire vs No Fire Detection Using Flame Dataset
Installing Basic EDA for Colab
"""

!pip install basic_image_eda

"""Importing required libraries"""

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import time
from basic_image_eda import BasicImageEDA

from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.layers import Activation, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

from google.colab import drive
drive.mount('/content/drive')

train_dir = "/content/drive/MyDrive/DS_Assignment/trainning/"
test_dir = "/content/drive/MyDrive/DS_Assignment/test/"

# train_dir = "Training/"
# test_dir = "Test/"

train_fire = train_dir+"Fire/"
train_no_fire = train_dir+"No_Fire/"
test_fire = test_dir+"Fire/"
test_no_fire = test_dir+"No_Fire/"

extensions = ['jpg']
threads = 0
dimension_plot = True
channel_hist = True
nonzero = False
hw_division_factor = 1.0

"""Performing Basic EDA for Train Fire and No Fire set"""

BasicImageEDA.explore(train_dir+"Fire/", extensions, 
                      threads, dimension_plot, channel_hist, nonzero, hw_division_factor)

BasicImageEDA.explore(train_dir+"No_Fire/", extensions, 
                      threads, dimension_plot, channel_hist, nonzero, hw_division_factor)

"""Checking class distribution for train set"""

train_fire = os.listdir(train_dir+"Fire/")
train_no_fire = os.listdir(train_dir+"No_Fire/")
print("fire example: ", len(train_fire))
print("no fire example: ", len(train_no_fire))

"""Analysing HSV histograms for Train Fire and No Fire set"""

n = 3
hist_fire = []
for j in range(n):    
    img_name = train_fire[np.random.choice(range(7000),1,replace=False)[0]]
    print(img_name)
    image = cv2.imread(train_dir+"Fire/"+img_name)
    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    fig = plt.figure(figsize=(15,25))
    fig.add_subplot(n,2,1)
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    fig.add_subplot(n,2,2)
    hist1 = cv2.calcHist([img_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
    hist_fire.append(hist1)
    plt.plot(hist1)
    plt.ylim([0, 1500])
    plt.show()

n = 3
hist_no_fire = []
for j in range(n):    
    img_name = train_no_fire[np.random.choice(range(7000),1,replace=False)[0]]
    print(img_name)
    image = cv2.imread(train_dir+"No_Fire/"+img_name)
    img_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    fig = plt.figure(figsize=(15,25))
    fig.add_subplot(n,2,1)
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    fig.add_subplot(n,2,2)
    hist2 = cv2.calcHist([img_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
    hist_no_fire.append(hist2)
    plt.plot(hist1)
    plt.ylim([0, 1500])
    plt.show()

"""Comparing histograms for data insight"""

for i in range(len(hist_fire)-1):
    temp = cv2.compareHist(hist_fire[i], hist_fire[i+1], 0)
    print("hist compare fire vs fire image samples\t\t", temp)
    temp = cv2.compareHist(hist_fire[i], hist_no_fire[i+1], 0)
    print("hist compare fire vs No fire image samples\t", temp)
    temp = cv2.compareHist(hist_no_fire[i], hist_no_fire[i+1], 0)
    print("hist compare No fire vs No fire image samples\t", temp, "\n")

"""Defining custom function to mask fire from images"""

lower = [0, 100, 100]
upper = [35, 255, 255]
lower = np.array(lower, dtype="uint8")
upper = np.array(upper, dtype="uint8")

def display(imgage, img_name):
    plt.figure(figsize=(15,10))
    plt.imshow(imgage)                                                                       
    plt.title(img_name)
    plt.show()
    
def transformFlame(input_img):
    img_rgb = input_img.astype(np.uint8)
#     display(img_rgb, "img_rgb")
    img_bgr = cv2.cvtColor(img_rgb.copy(), cv2.COLOR_RGB2BGR)
#     display(img_bgr, "img_bgr")
    img_blur = cv2.GaussianBlur(img_bgr.copy(), (1,1), 10)
#     display(img_blur, "img_blur")
    img_hsv = cv2.cvtColor(img_blur, cv2.COLOR_BGR2HSV)
#     display(img_hsv, "img_hsv")
    mask = cv2.inRange(img_hsv, lower, upper)
    output = cv2.bitwise_and(img_bgr, img_hsv, mask = mask)
#     display(output, "output")   
    output_rgb = cv2.cvtColor(output, cv2.COLOR_HSV2RGB)
#     display(output_rgb, "output_rgb")
    return output_rgb

"""Forming Train, Validation and Test generator"""

IMG_SIZE = 254
NB_CHANNELS = 3
BATCH_SIZE = 16
NB_TRAIN_IMG = 31501
NB_VALID_IMG = 7874
NB_TEST_IMG = 8617

train_datagen = ImageDataGenerator(
#                                    rescale=1.0/255.0, 
#                                    rotation_range=90, 
#                                    horizontal_flip=True, 
#                                    vertical_flip=True,
#                                    zoom_range=[0.5,1.0],
#                                    width_shift_range = 0.1,
#                                    height_shift_range = 0.1,
#                                    shear_range = 0.1,
#                                    fill_mode="nearest",
                                   validation_split=0.2,
                                   preprocessing_function=transformFlame
                                  )
test_datagen = ImageDataGenerator(
                                preprocessing_function=transformFlame
                                )

train_generator = train_datagen.flow_from_directory(train_dir, 
                                  batch_size=BATCH_SIZE,
                                  target_size=(254,254),
                                  color_mode="rgb",
                                  shuffle = True,
                                  class_mode='binary',
                                  subset='training'
                              )
validation_generator = train_datagen.flow_from_directory(train_dir, 
                                  batch_size=BATCH_SIZE,
                                  target_size=(254,254),
                                  color_mode="rgb",
                                  shuffle = True,
                                  class_mode='binary',
                                  subset='validation'                
                                )

test_generator = test_datagen.flow_from_directory(test_dir, 
                                  batch_size=BATCH_SIZE,
                                  target_size=(254,254),
                                  color_mode="rgb",
                                  shuffle = False,
                                  class_mode='binary'
                              )

print(train_generator.class_indices)
print(validation_generator.class_indices)

"""Verifying some samples from train generator output"""

def plotimages(images_arr):
    fix, axes = plt.subplots(4, 4, figsize=(15,10))
    axes = axes.flatten()
    for img, ax in zip(images_arr, axes):
        img = img.astype(np.uint8)
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

imgs, labels = next(train_generator)
plotimages(imgs)
print(labels)

"""Defining Deep CNN Model"""

cnn = Sequential()
cnn.add(Conv2D(filters=32,kernel_size=(2,2), strides=(1,1), padding='same',
               input_shape=(IMG_SIZE,IMG_SIZE,NB_CHANNELS), data_format='channels_last'))
cnn.add(Activation('relu'))
cnn.add(MaxPooling2D(pool_size=(2,2), strides=2))
cnn.add(Conv2D(filters=64, kernel_size=(2,2), strides=(1,1), padding='valid'))
cnn.add(Activation('relu'))
cnn.add(MaxPooling2D(pool_size=(2,2), strides=2))
cnn.add(Flatten())        
cnn.add(Dense(64))
cnn.add(Activation('relu'))
cnn.add(Dropout(0.25))
cnn.add(Dense(1))
cnn.add(Activation('sigmoid'))
cnn.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
cnn.summary()

"""Training the model and saving the best at early stopping"""

callbacks = [EarlyStopping(patience=10,verbose=2,monitor='val_loss',mode='min'),
             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]

start = time.time()
cnn.fit_generator(
    train_generator,
    steps_per_epoch=NB_TRAIN_IMG//BATCH_SIZE,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=NB_VALID_IMG//BATCH_SIZE,
    callbacks=callbacks)
end = time.time()
print('Processing time:',(end - start)/60)

"""Loading best model and evaluting it against test set"""

model = keras.models.load_model(filepath='best_model.h5')
scores = model.evaluate(test_generator, verbose=1)
print("Test Accuracy = ", scores[1])
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of bootstrap.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCi_99yMYIb1"
      },
      "source": [
        "In this notebook you'll create your own bootstrap function following the bootstrap algorithm (check the lecture notes!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5zujI2YC37",
        "pycharm": {
          "name": "#%%# Imports\n"
        }
      },
      "source": [
        "import matplotlib\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqkwj4SMY38t"
      },
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('/content/customers.csv')\n",
        "data = df.values.T[1]"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxvc_bScYC4H",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Checking the notes from the lecture, create here your own bootstrap function:\n",
        "# 1. Sample from the input array x to create an array of samples of shape (n_bootstraps, sample_size)\n",
        "# Hint: Check the function random.choice() on Numpy\n",
        "# 2. Calculate and save the mean of the array (this is \"data_mean\" that is returned by the function)\n",
        "# 3. Calculate the mean from each bootstrap (i.e., row) and store it.\n",
        "# (This should be an array of n_bootstraps values)\n",
        "# 4. Calculate the lower and upper bounds for a 95% CI (hint: check the percentile function on Numpy)\n",
        "# 5. Return data_mean, and the lower and upper bounds of your interval\n",
        "def bootstrap_mean(x, sample_size, n_bootstraps):\n",
        "  means = []\n",
        "  for i in range(n_bootstraps):\n",
        "    temp_list = []\n",
        "    for n in range(sample_size):\n",
        "      temp_list = np.append(temp_list, np.random.choice(x))\n",
        "    means = np.append(means, temp_list.mean())\n",
        "  data_mean = means.mean()\n",
        "  lower = np.percentile(means, 2.5, interpolation='lower')\n",
        "  upper = np.percentile(means, 97.5, interpolation='higher')\n",
        "\n",
        "  return data_mean, lower, upper"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN7sEOcMYC4P",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Call your bootstrap function and plot the results\n",
        "\n",
        "boots = []\n",
        "for i in range(100, 50000, 1000):\n",
        "    boot = bootstrap_mean(data, data.shape[0], i)\n",
        "    boots.append([i, boot[0], \"mean\"])\n",
        "    boots.append([i, boot[1], \"lower\"])\n",
        "    boots.append([i, boot[2], \"upper\"])\n",
        "\n",
        "df_boot = pd.DataFrame(boots, columns=['Bootstrap Iterations', 'Mean', \"Value\"])\n",
        "sns_plot = sns.lmplot(df_boot.columns[0], df_boot.columns[1], data=df_boot, fit_reg=False, hue=\"Value\")\n",
        "\n",
        "sns_plot.axes[0, 0].set_ylim(0,)\n",
        "sns_plot.axes[0, 0].set_xlim(0, 100000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjtP4e2_YC4V"
      },
      "source": [
        "\n",
        "Now, modify the bootstrap function you created above so that you can pass your desired confidence interval as a parameter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K9j0FuGYhHs"
      },
      "source": [
        "def bootstrap_mean_ci(sample, sample_size, n_bootstraps, ci):\n",
        "  means = []\n",
        "  for i in range(n_bootstraps):\n",
        "    temp_list = []\n",
        "    for n in range(sample_size):\n",
        "      temp_list = np.append(temp_list, np.random.choice(sample))\n",
        "    means = np.append(means, temp_list.mean())\n",
        "  data_mean = means.mean()\n",
        "  lower = np.percentile(means, (100 - ci) / 2, interpolation='lower')\n",
        "  upper = np.percentile(means, 100 - ((100 - ci) / 2), interpolation='higher')\n",
        "  \n",
        "  return data_mean, lower, upper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KbNWgPNdwuZ"
      },
      "source": [
        "def bootstrap_sd_ci(sample, sample_size, n_bootstraps, ci):\r\n",
        "  stds = []\r\n",
        "  for i in range(n_bootstraps):\r\n",
        "    temp_list = []\r\n",
        "    for n in range(sample_size):\r\n",
        "      temp_list = np.append(temp_list, np.random.choice(sample))\r\n",
        "    stds = np.append(stds, np.std(temp_list))\r\n",
        "  data_std = np.std(stds)\r\n",
        "  lower = np.percentile(stds, (100 - ci) / 2, interpolation='lower')\r\n",
        "  upper = np.percentile(stds, 100 - ((100 - ci) / 2), interpolation='higher')\r\n",
        "  return data_std, lower, upper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDnjq08GYl-C"
      },
      "source": [
        "boots = []\n",
        "for i in range(100, 50000, 1000):\n",
        "    boot = bootstrap_mean_ci(data, data.shape[0], i, 80)\n",
        "    boots.append([i, boot[0], \"mean\"])\n",
        "    boots.append([i, boot[1], \"lower\"])\n",
        "    boots.append([i, boot[2], \"upper\"])\n",
        "\n",
        "df_boot = pd.DataFrame(boots, columns=['Boostrap Iterations', 'Mean', \"Value\"])\n",
        "sns_plot = sns.lmplot(df_boot.columns[0], df_boot.columns[1], data=df_boot, fit_reg=False, hue=\"Value\")\n",
        "\n",
        "sns_plot.axes[0, 0].set_ylim(0,)\n",
        "sns_plot.axes[0, 0].set_xlim(0, 100000)\n",
        "\n",
        "#sns_plot.savefig(\"bootstrap_confidence_80.pdf\", bbox_inches='tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjNgXW6wdd7r"
      },
      "source": [
        "# Vehicles dataset\n",
        "\n",
        "Now let's work on a different dataset, which is stored in the vehicles.csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avWv4ipFdpka"
      },
      "source": [
        "# Load and visualise the vehicles dataset\n",
        "# To load the dataset: https://neptune.ai/blog/google-colab-dealing-with-files (check section \"Load individual files directly from GitHub\")\n",
        "\n",
        "\n",
        "# Note that the current and new fleets are in different columns and have different lengths, so bear this in mind when you're plotting.\n",
        "# You can create separate scatterplots for the two fleets, as you would with the histograms, \n",
        "# or plot them both in one plot (but not one against the other).\n",
        "# <---INSERT YOUR CODE HERE--->\n",
        "# Note: you can add more cells as needed to organise your code and your plots\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDU7FXzhOwRt"
      },
      "source": [
        "dfv = pd.read_csv('/content/vehicles.csv')\r\n",
        "print(\"Shape:\", dfv.shape)\r\n",
        "print(\"NAN: \\n\", dfv.isna().sum())\r\n",
        "dfv.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jknXAw20RTDR"
      },
      "source": [
        "sns.scatterplot(data=dfv, x=range(dfv.shape[0]), y=\"Current fleet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFokXhy2Svf4"
      },
      "source": [
        "sns.scatterplot(data=dfv, x=range(dfv.shape[0]), y=\"New Fleet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5d0tXDpIEj8"
      },
      "source": [
        "## Compare the two fleets\r\n",
        "\r\n",
        "The business analysts come up a comparison algorithm that requires the upper and lower bounds for the mean in order to say which fleet is better.\r\n",
        "1. Calculate the mean of both samples.\r\n",
        "2. Using the bootstrap function that you created:\r\n",
        "    - Construct the 95% CI of the mean of the current fleet.\r\n",
        "    - Construct the 95% CI of the mean of the new fleet.\r\n",
        "    - Are they comparable? (i.e., is one better than the other?) -- you can do this with a permutation test (check the lecture notes!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJsw5eypalgU"
      },
      "source": [
        "cfleet = dfv[\"Current fleet\"]\r\n",
        "nfleet = dfv[\"New Fleet\"].dropna()\r\n",
        "\r\n",
        "cfleet = np.array(cfleet)\r\n",
        "nfleet = np.array(nfleet)\r\n",
        "\r\n",
        "x_old = cfleet.mean()\r\n",
        "x_new = nfleet.mean()\r\n",
        "print(x_old)\r\n",
        "print(x_new)\r\n",
        "t_obs = x_new - x_old\r\n",
        "print(t_obs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THgWmi9FY7WC"
      },
      "source": [
        "cf_boot = bootstrap_mean_ci(cfleet, cfleet.shape[0], 50000, 95)\r\n",
        "print(cf_boot)\r\n",
        "\r\n",
        "nf_boot = bootstrap_mean_ci(nfleet, nfleet.shape[0], 50000, 95)\r\n",
        "print(nf_boot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkxvDZG4HC0n"
      },
      "source": [
        "# Create your own function for a permutation test here (you will need it for the lab quiz!):\n",
        "def permut_test(sample1, sample2, n_permutations):\n",
        "    \"\"\"\n",
        "    sample1: 1D array\n",
        "    sample2: 1D array (note that the size of the two arrays can be different)\n",
        "    n_permutations: number of permutations to calculate the p-value\n",
        "    \"\"\"\n",
        "    concat = np.concatenate([sample1, sample2])\n",
        "    counter = 0\n",
        "    for i in range(n_permutations):\n",
        "      perm = np.random.permutation(concat)\n",
        "      pold = perm[:len(sample1)]\n",
        "      pnew = perm[len(sample1):]\n",
        "      x_perm_old = pold.mean()\n",
        "      x_perm_new = pnew.mean()\n",
        "      t_perm = x_perm_new - x_perm_old\n",
        "      if (t_perm > t_obs):\n",
        "        counter +=1\n",
        "    pvalue = counter / n_permutations\n",
        "    return pvalue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JILvfmgobYv8"
      },
      "source": [
        "permut_test(cfleet, nfleet, 30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWQ6rb-bc_Ec"
      },
      "source": [
        "Quiz Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IHYAzac0v-A"
      },
      "source": [
        "Q2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n1vqvLkzSQk"
      },
      "source": [
        "cboot = bootstrap_mean_ci(cfleet, len(cfleet), 10000, 92)\r\n",
        "print(cboot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Yp6ilg0yqs"
      },
      "source": [
        "Q3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROMhI690zTkn"
      },
      "source": [
        "cboot = bootstrap_mean_ci(nfleet, len(nfleet), 10000, 95)\r\n",
        "print(cboot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quQxE3VO00FC"
      },
      "source": [
        "Q4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BY4qt4me5Bd"
      },
      "source": [
        "cboot = bootstrap_sd_ci(nfleet, len(nfleet), 10000, 95)\r\n",
        "print(cboot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6evYG-RQ1Xq-"
      },
      "source": [
        "Q5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9MOTo801NFe",
        "outputId": "2dc5bed9-e8fc-4465-e06b-ccda3ccdbb8f"
      },
      "source": [
        "cboot = bootstrap_sd_ci(data, data.shape[0], 10000, 90)\r\n",
        "print(cboot)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1.1967258447797429, 3.0380243311623913, 7.109995831117439)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9YYL-4j01lq"
      },
      "source": [
        "Q7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDqGfklKz6xY"
      },
      "source": [
        "permut_test(cfleet, nfleet, 30000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z8CkvoYhZ2d"
      },
      "source": [
        "# The variables below represent the percentages of democratic votes in Pennsylvania and Ohio (one value for each state).\r\n",
        "dem_share_PA = [60.08, 40.64, 36.07, 41.21, 31.04, 43.78, 44.08, 46.85, 44.71, 46.15, 63.10, 52.20, 43.18, 40.24, 39.92, 47.87, 37.77, 40.11, 49.85, 48.61, 38.62, 54.25, 34.84, 47.75, 43.82, 55.97, 58.23, 42.97, 42.38, 36.11, 37.53, 42.65, 50.96, 47.43, 56.24, 45.60, 46.39, 35.22, 48.56, 32.97, 57.88, 36.05, 37.72, 50.36, 32.12, 41.55, 54.66, 57.81, 54.58, 32.88, 54.37, 40.45, 47.61, 60.49, 43.11, 27.32, 44.03, 33.56, 37.26, 54.64, 43.12, 25.34, 49.79, 83.56, 40.09, 60.81, 49.81]\r\n",
        "dem_share_OH = [56.94, 50.46, 65.99, 45.88, 42.23, 45.26, 57.01, 53.61, 59.10, 61.48, 43.43, 44.69, 54.59, 48.36, 45.89, 48.62, 43.92, 38.23, 28.79, 63.57, 38.07, 40.18, 43.05, 41.56, 42.49, 36.06, 52.76, 46.07, 39.43, 39.26, 47.47, 27.92, 38.01, 45.45, 29.07, 28.94, 51.28, 50.10, 39.84, 36.43, 35.71, 31.47, 47.01, 40.10, 48.76, 31.56, 39.86, 45.31, 35.47, 51.38, 46.33, 48.73, 41.77, 41.32, 48.46, 53.14, 34.01, 54.74, 40.67, 38.96, 46.29, 38.25, 6.80, 31.75, 46.33, 44.90, 33.57, 38.10, 39.67, 40.47, 49.44, 37.62, 36.71, 46.73, 42.20, 53.16, 52.40, 58.36, 68.02, 38.53, 34.58, 69.64, 60.50, 53.53, 36.54, 49.58, 41.97, 38.11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu8A7P9C06Ff"
      },
      "source": [
        "Q8.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MsHuCm3guVN"
      },
      "source": [
        "print(\"dem_share_PA \", len(dem_share_PA))\r\n",
        "print(\"dem_share_OH \", len(dem_share_OH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuhBAY4k1i3w"
      },
      "source": [
        "Q8.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD-R6FNBhp-4"
      },
      "source": [
        "cboot = bootstrap_mean_ci(dem_share_OH, len(dem_share_OH), 200000, 95)\r\n",
        "print(cboot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwCNHM2p1zsT"
      },
      "source": [
        "Q8.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMnuR5w50b6M"
      },
      "source": [
        "cboot = bootstrap_mean_ci(dem_share_PA, len(dem_share_PA), 200000, 95)\r\n",
        "print(cboot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar88wC3311Ww"
      },
      "source": [
        "Q8.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpc5TQ7Gh9Zg"
      },
      "source": [
        "permut_test(dem_share_PA, dem_share_OH, 10000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}